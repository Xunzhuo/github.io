<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta name="google-site-verification" content="TZE0rZyIqLl10trYu3BWBWa1Vmz6HFwhb2OcNEK4u-s" />
     <link rel="shortcut icon" href= https://picreso.oss-cn-beijing.aliyuncs.com/favicon.ico >
    <title>
        Coder主题 - 刘训灼
    </title>
    <meta name="description" content= 嘿，我是刘训灼～这里用于展示写的Hexo主题：Coder。 >
    <meta name="keywords" content= Blog,Hexo,Theme,刘训灼,LiuXunzhuo >
    
<link rel="stylesheet" href="/libs/highlight/styles/monokai-sublime.css">

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>
<body id="bodyx">
    <div class="hd posts">
    <a href="/index.html"><i class="fa fa-home
 replay-btn" aria-hidden="true"></i></a>
    <div class="post-title">
        <p>
            如何用神经网络预测股票趋势❓
        </p>
        <hr>
    </div>
    <div class="post-content">
        <p><img src="https://picreso.oss-cn-beijing.aliyuncs.com/stock1.jpg" alt=""></p>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>疫情期间，我爸妈又开始炒股了，鉴于之前做过一个AI结合的量化交易项目，但是不是负责算法部分，所以想自己尝试一下，实现一个算法引擎。</p>
<p>纯数据科学只能做参考，最好结合传统量化交易和舆情分析，我后面有时间会尝试三者结合，希望有更好效果。</p>
<hr>
<p>在本教程中，你将了解到如何使用被称作长短期记忆网络（LSTM）的时间序列模型。LSTM 模型在保持长期记忆方面非常强大。阅读这篇教程时，你将：</p>
<ul>
<li>明白预测股市走势的动机；</li>
<li>下载股票数据 — 你将使用由 Alpha Vantage 或 Kaggle 收集的股票数据；</li>
<li>将数据划分为训练集和测试集，并将其标准化；</li>
<li>简要讨论一下为什么 LSTM 模型可以预测未来多步的情形；</li>
<li>使用现有数据预测股票趋势，并将结果可视化。</li>
</ul>
<p><strong>注意：请不要认为 LSTM 是一种可以完美预测股票趋势的可靠模型，也不要盲目使用它进行股票交易</strong>。我只是出于对机器学习的兴趣做了这个实验。在大部分情况下，这个模型的确能发现数据中的特定规律并准确预测股票的走势。但是否将其用于实际的股票市场取决于你自己。</p>
<h3 id="为什么要用时间序列模型？"><a href="#为什么要用时间序列模型？" class="headerlink" title="为什么要用时间序列模型？"></a>为什么要用时间序列模型？</h3><p>作为一名股民，如果你能对股票价格进行正确的建模，你就可以通过在合适的时机买入或卖出来获取利益。因此，你需要能通过一组历史数据来预测未来数据的模型——时间序列模型。</p>
<p><strong>警告</strong>：股价本身因受到诸多因素影响而难以预测，这意味着你难以找到一种能完美预测股价的模型。并不只有我一人如此认为。普林斯顿大学的经济学教授 Burton Malkiel 在他 1973 年出版的《A Random Walk Down Wall Street》一书中写道：“如果股市足够高效，以至于人们能从公开的股价中知晓影响它的全部因素，那么人人都能像投资专业人士那样炒股”。</p>
<p>但是，请保持信心，用机器学习的方法来预测这完全随机的股价仍有一丝希望。我们至少能通过建模来预测这组数据的实际走势。换而言之，不必知晓股价的确切值，你只要能预测股价要涨还是要跌就万事大吉了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 请确保你安装了这些包，并且能运行成功以下代码</span></span><br><span class="line"><span class="keyword">from</span> pandas_datareader <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> datetime <span class="keyword">as</span> dt</span><br><span class="line"><span class="keyword">import</span> urllib.request, json </span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf <span class="comment"># TensorFlow 1.6 版本下测试通过</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br></pre></td></tr></table></figure>

<h3 id="下载数据"><a href="#下载数据" class="headerlink" title="下载数据"></a>下载数据</h3><p>你可以从以下来源下载数据：</p>
<ol>
<li>Alpha Vantage。首先，你必须从 <a href="https://www.alphavantage.co/support/#api-key" target="_blank" rel="noopener">这个网站</a> 获取所需的 API key。在此之后，将它的值赋给变量 <code>api_key</code>。</li>
<li>从 <a href="https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs" target="_blank" rel="noopener">这个页面</a> 下载并将其中的 <em>Stocks</em> 文件夹拷贝到你的工程目录下。</li>
</ol>
<p>股价中包含几种不同的数据，它们是：</p>
<ul>
<li>开盘价：一天中股票刚开盘时的价格；</li>
<li>收盘价：一天中股票收盘时的价格；</li>
<li>最高价：一天中股价的最大值；</li>
<li>最低价：一天中股价的最小值。</li>
</ul>
<h3 id="从-Alpha-Vantage-获取数据"><a href="#从-Alpha-Vantage-获取数据" class="headerlink" title="从 Alpha Vantage 获取数据"></a>从 Alpha Vantage 获取数据</h3><p>为了从 Alpha Vantage 上下载美国航空公司的股价数据用于分析，你要将行情显示代号 <code>ticker</code> 设置为 <code>&quot;AAL&quot;</code>。同时，你也要定义一个 <code>url_string</code> 变量来获取包含最近 20 年内的全部股价信息的 JSON 文件，以及文件保存路径 <code>file_to_save</code>。别忘了用你的 <code>ticker</code> 变量来帮助你命名你下载下来的文件。</p>
<p>接下来，设定一个条件：如果本地没有保存的数据文件，就从 <code>url_string</code> 指明的 URL 下载数据，并将其中的日期、最低价、最高价、交易量、开盘价和收盘价存入 Pandas 的 DataFrame <code>df</code> 中，再将其保存到 <code>file_to_save</code>；否则直接从本地读取 csv 文件就好了。</p>
<h3 id="从-Kaggle-获取数据"><a href="#从-Kaggle-获取数据" class="headerlink" title="从 Kaggle 获取数据"></a>从 Kaggle 获取数据</h3><p>从 Kaggle 上找到的数据是一系列 csv 表格，你不需要对它进行任何处理就可以直接读入 Pandas 的 DataFrame 中。确保你正确地将 <em>Stocks</em> 文件夹放在项目的主目录中。</p>
<h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><p>现在，将这些数据打印到 DataFrame 中吧！由于数据的顺序在时间序列模型中至关重要，所以请确保你的数据已经按照日期排好序了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按日期排序</span></span><br><span class="line">df = df.sort_values(<span class="string">'Date'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查结果</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>

<h4 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h4><p>看看你的数据，并从中找到伴随时间推移而具有的不同规律。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">18</span>,<span class="number">9</span>))</span><br><span class="line">plt.plot(range(df.shape[<span class="number">0</span>]),(df[<span class="string">'Low'</span>]+df[<span class="string">'High'</span>])/<span class="number">2.0</span>)</span><br><span class="line">plt.xticks(range(<span class="number">0</span>,df.shape[<span class="number">0</span>],<span class="number">500</span>),df[<span class="string">'Date'</span>].loc[::<span class="number">500</span>],rotation=<span class="number">45</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Date'</span>,fontsize=<span class="number">18</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Mid Price'</span>,fontsize=<span class="number">18</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>



<img src="https://picreso.oss-cn-beijing.aliyuncs.com/stock11.png" alt="" style="zoom:50%;" />



<p>这幅图包含了很多信息。我特意选取了这家公司的股价图，因为它包含了股价的多种不同规律。这将使你的模型更健壮，也让它能更好地预测不同情形下的股价。</p>
<p>另一件值得注意的事情是 2017 年的股价远比上世纪七十年代的股价高且波动更大。因此，你要在<strong>数据标准化</strong>的过程中，注意让这些部分的数据落在相近的数值区间内。</p>
<h3 id="将数据划分为训练集和测试集"><a href="#将数据划分为训练集和测试集" class="headerlink" title="将数据划分为训练集和测试集"></a>将数据划分为训练集和测试集</h3><p>首先通过对每一天的最高和最低价的平均值来算出 <code>mid_prices</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先用最高和最低价来算出中间价</span></span><br><span class="line">high_prices = df.loc[:,<span class="string">'High'</span>].as_matrix()</span><br><span class="line">low_prices = df.loc[:,<span class="string">'Low'</span>].as_matrix()</span><br><span class="line">mid_prices = (high_prices+low_prices)/<span class="number">2.0</span></span><br></pre></td></tr></table></figure>

<p>然后你就可以划分数据集了。前 11000 个数据属于训练集，剩下的都属于测试集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data = mid_prices[:<span class="number">11000</span>] </span><br><span class="line">test_data = mid_prices[<span class="number">11000</span>:]</span><br></pre></td></tr></table></figure>

<p>接下来我们需要一个换算器 <code>scaler</code> 用于标准化数据。<code>MinMaxScalar</code> 会将所有数据换算到 0 和 1 之间。同时，你也可以将两个数据集都调整为 <code>[data_size, num_features]</code> 的大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将所有数据缩放到 0 和 1 之间</span></span><br><span class="line"><span class="comment"># 在缩放时请注意，缩放测试集数据时请使用缩放训练集数据的参数</span></span><br><span class="line"><span class="comment"># 因为在测试前你是不应当知道测试集数据的</span></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">train_data = train_data.reshape(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line">test_data = test_data.reshape(<span class="number">-1</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>上面我们注意到不同年代的股价处于不同的价位，如果不做特殊处理的话，在标准化后的数据中，上世纪的股价数据将非常接近于 0。这对模型的学习过程没啥好处。所以我们将整个时间序列划分为若干个区间，并在每一个区间上做标准化。这里每一个区间的长度取值为 2500。</p>
<p><strong>提示</strong>：因为每一个区间都被独立地初始化，所以在两个区间的交界处会引入一个“突变”。为了避免这个“突变”给我们的模型带来大麻烦，这里的每一个区间长度不要太小。</p>
<p>本例中会引入 4 个“突变”，鉴于数据有 11000 组，所以它们无关紧要。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用训练集来训练换算器 scaler，并且调整数据使之更平滑</span></span><br><span class="line">smoothing_window_size = <span class="number">2500</span></span><br><span class="line"><span class="keyword">for</span> di <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10000</span>,smoothing_window_size):</span><br><span class="line">    scaler.fit(train_data[di:di+smoothing_window_size,:])</span><br><span class="line">    train_data[di:di+smoothing_window_size,:] = scaler.transform(train_data[di:di+smoothing_window_size,:])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化所有的数据</span></span><br><span class="line">scaler.fit(train_data[di+smoothing_window_size:,:])</span><br><span class="line">train_data[di+smoothing_window_size:,:] = scaler.transform(train_data[di+smoothing_window_size:,:])</span><br></pre></td></tr></table></figure>

<p>将数据矩阵调整回 <code>[data_size]</code> 的形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新调整测试集和训练集</span></span><br><span class="line">train_data = train_data.reshape(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将测试集标准化</span></span><br><span class="line">test_data = scaler.transform(test_data).reshape(<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>

<p>为了产生一条更平滑的曲线，我们使用一种叫做指数加权平均的算法。</p>
<p><strong>注意</strong>：我们只使用训练集来训练换算器 <code>scaler</code>，否则在标准化测试集时将得到不准确的结果。</p>
<p><strong>注意</strong>：只允许对训练集做平滑处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 应用指数加权平均</span></span><br><span class="line"><span class="comment"># 现在数据将比之间更为平滑</span></span><br><span class="line">EMA = <span class="number">0.0</span></span><br><span class="line">gamma = <span class="number">0.1</span></span><br><span class="line"><span class="keyword">for</span> ti <span class="keyword">in</span> range(<span class="number">11000</span>):</span><br><span class="line">  EMA = gamma*train_data[ti] + (<span class="number">1</span>-gamma)*EMA</span><br><span class="line">  train_data[ti] = EMA</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用于可视化和调试</span></span><br><span class="line">all_mid_data = np.concatenate([train_data,test_data],axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="评估结果"><a href="#评估结果" class="headerlink" title="评估结果"></a>评估结果</h3><p>为了评估训练出来的模型，我们将计算其预测值与真实值的均方误差（MSE）。将每一个预测值与真实值误差的平方取均值，即为这个模型的均方误差。</p>
<h3 id="股价建模中的平均值"><a href="#股价建模中的平均值" class="headerlink" title="股价建模中的平均值"></a>股价建模中的平均值</h3><blockquote>
<p>取平均值在预测单步上效果不错，但对股市预测这种需要预测许多步的情形不适用。</p>
</blockquote>
<h3 id="使用-LSTM-预测未来股价走势"><a href="#使用-LSTM-预测未来股价走势" class="headerlink" title="使用 LSTM 预测未来股价走势"></a>使用 LSTM 预测未来股价走势</h3><p>长短期记忆网络模型是非常强大的基于时间序列的模型，它们能向后预测任意步。一个 LSTM 模块（或者一个 LSTM 单元）使用 5 个重要的参数来对长期和短期数据建模。</p>
<ul>
<li>单元状态（$c_{t}$）- 这代表了单元存储的短期和长期记忆；</li>
<li>隐藏状态（$h_{t}$）- 这是根据当前输入、以前的隐藏状态和当前单元输入计算的用于预测未来股价的输出状态信息 。此外，隐藏状态还决定着是否只使用单元状态中的记忆（短期、长期或两者都使用）来进行下一次预测；</li>
<li>输入门（$i_{t}$）- 从输入门流入到单元状态中的信息；</li>
<li>遗忘门（$f_{t}$）- 从当前输入和前一个单元状态流到当前单元状态的信息；</li>
<li>输出门（$o_{t}$）- 从当前单元状态流到隐藏状态的信息，这决定了 LSTM 接下来使用的记忆类型。</li>
</ul>
<p>下图展示了一个 LSTM 单元。</p>
<img src="https://picreso.oss-cn-beijing.aliyuncs.com/stock111.png" alt="" style="zoom:50%;" />

<p>其中计算的算式如下：</p>
<img src="https://picreso.oss-cn-beijing.aliyuncs.com/stock11111.png" alt="" style="zoom:50%;" />

<h3 id="数据生成器"><a href="#数据生成器" class="headerlink" title="数据生成器"></a>数据生成器</h3><p>最简单的想法是将总量为 N 的数据集，平均分割成 N/b 个序列，每个序列包含 b 个数据点。然后我们假想若干个指针，它们指向每一个序列的第一个元素。然后我们就可以开始采样生成数据了。我们将当前段的指针指向的元素下标当作输入，并在其后面的 1~5 个元素中随机挑选一个作为正确的预测值，因为模型并不总是只预测紧靠当前时间点的后一个数据。这样可以有效避免过拟合。每一次取样之后，我们将指针的下标加一，并开始生成下一个数据点。</p>
<img src="https://picreso.oss-cn-beijing.aliyuncs.com/stock1123.png" alt="" style="zoom:50%;" />



<h3 id="定义超参数"><a href="#定义超参数" class="headerlink" title="定义超参数"></a>定义超参数</h3><p>在本节中，我们将定义若干个超参数。<code>D</code> 是输入的维数。因为你使用前一天的股价来预测后面的股价，所以 <code>D</code> 应当是 <code>1</code>。</p>
<p><code>num_unrollings</code> 表示单个步骤中考虑的连续时间点个数，越大越好。</p>
<p>然后是 <code>batch_size</code>。它是在单个时间点中考虑的数据样本数量。它越大越好，因为选取的样本数量越大，模型可以参考的数据也就更多。</p>
<p>最后是 <code>num_nodes</code> 决定了每个单元中包含了多少隐藏神经元。在本例中，网络中包含三层 LSTM。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">D = <span class="number">1</span> <span class="comment"># 数据的维度</span></span><br><span class="line">num_unrollings = <span class="number">50</span> <span class="comment"># 你想预测多远的结果</span></span><br><span class="line">batch_size = <span class="number">500</span> <span class="comment"># 一次批处理中包含的数据个数</span></span><br><span class="line">num_nodes = [<span class="number">200</span>,<span class="number">200</span>,<span class="number">150</span>] <span class="comment"># 使用的深层 LSTM 网络的每一层中的隐藏节点数</span></span><br><span class="line">n_layers = len(num_nodes) <span class="comment"># 层数</span></span><br><span class="line">dropout = <span class="number">0.2</span> <span class="comment"># dropout 概率</span></span><br><span class="line"></span><br><span class="line">tf.reset_default_graph() <span class="comment"># 如果你想要多次运行，这个语句至关重要</span></span><br></pre></td></tr></table></figure>

<h3 id="定义输入和输出"><a href="#定义输入和输出" class="headerlink" title="定义输入和输出"></a>定义输入和输出</h3><p>接下来定义用于输入训练数据和标签的 placeholder。因为每个 placeholder 中只包含一批一维数据，所以这并不难。对于每一个优化步骤，我们需要 <code>num_unrollings</code> 个 placeholder。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入数据</span></span><br><span class="line">train_inputs, train_outputs = [],[]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据时间顺序展开输入，为每个时间点定义一个 placeholder</span></span><br><span class="line"><span class="keyword">for</span> ui <span class="keyword">in</span> range(num_unrollings):</span><br><span class="line">    train_inputs.append(tf.placeholder(tf.float32, shape=[batch_size,D],name=<span class="string">'train_inputs_%d'</span>%ui))</span><br><span class="line">    train_outputs.append(tf.placeholder(tf.float32, shape=[batch_size,<span class="number">1</span>], name = <span class="string">'train_outputs_%d'</span>%ui))</span><br></pre></td></tr></table></figure>

<h3 id="定义-LSTM-和回归层的参数"><a href="#定义-LSTM-和回归层的参数" class="headerlink" title="定义 LSTM 和回归层的参数"></a>定义 LSTM 和回归层的参数</h3><p>您将有一个包含三层 LSTM 和一层线性回归层的神经网络，分别用 <code>w</code> 和 <code>b</code> 表示，它获取上一个长短期记忆单元的输出，并输出对下一个时间的预测。你可以使用 TensorFlow 中的 <code>MultiRNNCell</code> 来封装您创建的三个 <code>LSTMCell</code> 对象。此外，LSTM 单元上还可以加上 dropout 来提高性能并减少过拟合。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">stm_cells = [</span><br><span class="line">    tf.contrib.rnn.LSTMCell(num_units=num_nodes[li],</span><br><span class="line">                            state_is_tuple=<span class="literal">True</span>,</span><br><span class="line">                            initializer= tf.contrib.layers.xavier_initializer()</span><br><span class="line">                           )</span><br><span class="line"> <span class="keyword">for</span> li <span class="keyword">in</span> range(n_layers)]</span><br><span class="line"></span><br><span class="line">drop_lstm_cells = [tf.contrib.rnn.DropoutWrapper(</span><br><span class="line">    lstm, input_keep_prob=<span class="number">1.0</span>,output_keep_prob=<span class="number">1.0</span>-dropout, state_keep_prob=<span class="number">1.0</span>-dropout</span><br><span class="line">) <span class="keyword">for</span> lstm <span class="keyword">in</span> lstm_cells]</span><br><span class="line">drop_multi_cell = tf.contrib.rnn.MultiRNNCell(drop_lstm_cells)</span><br><span class="line">multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)</span><br><span class="line"></span><br><span class="line">w = tf.get_variable(<span class="string">'w'</span>,shape=[num_nodes[<span class="number">-1</span>], <span class="number">1</span>], initializer=tf.contrib.layers.xavier_initializer())</span><br><span class="line">b = tf.get_variable(<span class="string">'b'</span>,initializer=tf.random_uniform([<span class="number">1</span>],<span class="number">-0.1</span>,<span class="number">0.1</span>))</span><br></pre></td></tr></table></figure>

<h3 id="计算-LSTM-输出并将结果代入回归层进行预测"><a href="#计算-LSTM-输出并将结果代入回归层进行预测" class="headerlink" title="计算 LSTM 输出并将结果代入回归层进行预测"></a>计算 LSTM 输出并将结果代入回归层进行预测</h3><p>在本节中，首先创建 TensorFlow 张量 <code>c</code> 和 <code>h</code> 用来保存 LSTM 单元的单元状态和隐藏状态。然后将 <code>train_input</code> 转换为 <code>[num_unrollings, batch_size, D]</code> 的形状，这是计算 <code>tf.nn.dynamic_rnn</code> 函数的输出所必需的。然后用 <code>tf.nn.dynamic_rnn</code> 计算 LSTM 输出，并将输出转化为一系列 <code>num_unrolling</code> 张量来预测和真实股价之间的损失函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 LSTM 的单元状态 c 和隐藏状态 h</span></span><br><span class="line">c, h = [],[]</span><br><span class="line">initial_state = []</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> range(n_layers):</span><br><span class="line">  c.append(tf.Variable(tf.zeros([batch_size, num_nodes[li]]), trainable=<span class="literal">False</span>))</span><br><span class="line">  h.append(tf.Variable(tf.zeros([batch_size, num_nodes[li]]), trainable=<span class="literal">False</span>))</span><br><span class="line">  initial_state.append(tf.contrib.rnn.LSTMStateTuple(c[li], h[li]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为 dynamic_rnn 函数需要特定的输出格式，所以我们对张量进行一些变换</span></span><br><span class="line"><span class="comment"># 请访问 https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn 来了解更多</span></span><br><span class="line">all_inputs = tf.concat([tf.expand_dims(t,<span class="number">0</span>) <span class="keyword">for</span> t <span class="keyword">in</span> train_inputs],axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># all_outputs 张量的尺寸是 [seq_length, batch_size, num_nodes]</span></span><br><span class="line">all_lstm_outputs, state = tf.nn.dynamic_rnn(</span><br><span class="line">    drop_multi_cell, all_inputs, initial_state=tuple(initial_state),</span><br><span class="line">    time_major = <span class="literal">True</span>, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">all_lstm_outputs = tf.reshape(all_lstm_outputs, [batch_size*num_unrollings,num_nodes[<span class="number">-1</span>]])</span><br><span class="line"></span><br><span class="line">all_outputs = tf.nn.xw_plus_b(all_lstm_outputs,w,b)</span><br><span class="line"></span><br><span class="line">split_outputs = tf.split(all_outputs,num_unrollings,axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="损失函数的计算与优化"><a href="#损失函数的计算与优化" class="headerlink" title="损失函数的计算与优化"></a>损失函数的计算与优化</h3><p>然后计算损失函数。但是在计算它时有一个值得注意的点。对于每批预测和真实输出，计算均方误差。然后将这些均方损失加起来（而非平均值）。最后，定义用于优化神经网络的优化器。我推荐使用 Adam 这种最新的、性能良好的优化器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在计算损失函数时，你需要注意准确的计算方法</span></span><br><span class="line"><span class="comment"># 因为你要同时计算所有展开步骤的损失函数</span></span><br><span class="line"><span class="comment"># 因此，在展开时取每批数据的平均误差，并将它们相加得到最终损失函数</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Defining training Loss'</span>)</span><br><span class="line">loss = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies([tf.assign(c[li], state[li][<span class="number">0</span>]) <span class="keyword">for</span> li <span class="keyword">in</span> range(n_layers)]+</span><br><span class="line">                             [tf.assign(h[li], state[li][<span class="number">1</span>]) <span class="keyword">for</span> li <span class="keyword">in</span> range(n_layers)]):</span><br><span class="line">  <span class="keyword">for</span> ui <span class="keyword">in</span> range(num_unrollings):</span><br><span class="line">    loss += tf.reduce_mean(<span class="number">0.5</span>*(split_outputs[ui]-train_outputs[ui])**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Learning rate decay operations'</span>)</span><br><span class="line">global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">inc_gstep = tf.assign(global_step,global_step + <span class="number">1</span>)</span><br><span class="line">tf_learning_rate = tf.placeholder(shape=<span class="literal">None</span>,dtype=tf.float32)</span><br><span class="line">tf_min_learning_rate = tf.placeholder(shape=<span class="literal">None</span>,dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">learning_rate = tf.maximum(</span><br><span class="line">    tf.train.exponential_decay(tf_learning_rate, global_step, decay_steps=<span class="number">1</span>, decay_rate=<span class="number">0.5</span>, staircase=<span class="literal">True</span>),</span><br><span class="line">    tf_min_learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化器</span></span><br><span class="line">print(<span class="string">'TF Optimization operations'</span>)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate)</span><br><span class="line">gradients, v = zip(*optimizer.compute_gradients(loss))</span><br><span class="line">gradients, _ = tf.clip_by_global_norm(gradients, <span class="number">5.0</span>)</span><br><span class="line">optimizer = optimizer.apply_gradients(</span><br><span class="line">    zip(gradients, v))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\tAll done'</span>)</span><br></pre></td></tr></table></figure>

<p>这里定义与预测相关的 TensorFlow 操作。首先，定义用于输入的占位符（<code>sample_input</code>）。然后像训练阶段那样，定义用于预测的状态变量（<code>sample_c</code> 和 <code>sample_h</code>）。再然后用 <code>tf.nn.dynamic_rnn</code> 函数计算预测值。最后通过线性回归层（<code>w</code> 和 <code>b</code>）发送输出。您还应该定义 <code>reset_sample_state</code> 操作用于重置单元格状态和隐藏状态。每次进行一系列预测时，都应该在开始时执行此操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Defining prediction related TF functions'</span>)</span><br><span class="line"></span><br><span class="line">sample_inputs = tf.placeholder(tf.float32, shape=[<span class="number">1</span>,D])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在预测阶段更新 LSTM 状态</span></span><br><span class="line">sample_c, sample_h, initial_sample_state = [],[],[]</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> range(n_layers):</span><br><span class="line">  sample_c.append(tf.Variable(tf.zeros([<span class="number">1</span>, num_nodes[li]]), trainable=<span class="literal">False</span>))</span><br><span class="line">  sample_h.append(tf.Variable(tf.zeros([<span class="number">1</span>, num_nodes[li]]), trainable=<span class="literal">False</span>))</span><br><span class="line">  initial_sample_state.append(tf.contrib.rnn.LSTMStateTuple(sample_c[li],sample_h[li]))</span><br><span class="line"></span><br><span class="line">reset_sample_states = tf.group(*[tf.assign(sample_c[li],tf.zeros([<span class="number">1</span>, num_nodes[li]])) <span class="keyword">for</span> li <span class="keyword">in</span> range(n_layers)],</span><br><span class="line">                               *[tf.assign(sample_h[li],tf.zeros([<span class="number">1</span>, num_nodes[li]])) <span class="keyword">for</span> li <span class="keyword">in</span> range(n_layers)])</span><br><span class="line"></span><br><span class="line">sample_outputs, sample_state = tf.nn.dynamic_rnn(multi_cell, tf.expand_dims(sample_inputs,<span class="number">0</span>),</span><br><span class="line">                                   initial_state=tuple(initial_sample_state),</span><br><span class="line">                                   time_major = <span class="literal">True</span>,</span><br><span class="line">                                   dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies([tf.assign(sample_c[li],sample_state[li][<span class="number">0</span>]) <span class="keyword">for</span> li <span class="keyword">in</span> range(n_layers)]+</span><br><span class="line">                              [tf.assign(sample_h[li],sample_state[li][<span class="number">1</span>]) <span class="keyword">for</span> li <span class="keyword">in</span> range(n_layers)]):  </span><br><span class="line">  sample_prediction = tf.nn.xw_plus_b(tf.reshape(sample_outputs,[<span class="number">1</span>,<span class="number">-1</span>]), w, b)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\tAll done'</span>)</span><br></pre></td></tr></table></figure>

<h3 id="运行-LSTM"><a href="#运行-LSTM" class="headerlink" title="运行 LSTM"></a>运行 LSTM</h3><p>在这里，你将训练并预测股票价格在接下来一段时间内的变动趋势，并观察预测是否正确。按照以下步骤操作我的 Jupyter Notebook（我制作好后会发布在GitHub上）。</p>
<blockquote>
<p>★ 在时间序列上定义一系列起始点 <code>test_points_seq</code> 用于评估你的模型</p>
<p>★ 对于每一个时间点</p>
<p>★★ 对于全部的训练数据</p>
<p>★★★ 将 <code>num_unrollings</code> 展开</p>
<p>★★★ 使用展开的数据训练神经网络</p>
<p>★★ 计算训练的平均损失函数</p>
<p>★★ 对于测试集中的每一个起始点</p>
<p>★★★ 通过迭代测试点之前找到的 <code>num_unrollings</code> 中的数据点来更新 LSTM 状态</p>
<p>★★★ 连续预测接下来的 <code>n_predict_once</code> 步，然后将前一次的预测作为本次的输入</p>
<p>★★★ 计算预测值和真实股价之间的均方误差</p>
</blockquote>
<h3 id="将预测结果可视化"><a href="#将预测结果可视化" class="headerlink" title="将预测结果可视化"></a>将预测结果可视化</h3><p>你可以发现，模型的均方误差在显著地下降，这意味着模型确实学习到了有用的信息。你可以通过比较神经网络产生的均方误差以及对股价取标准平均的均方误差（0.004）来量化你的成果。显然，LSTM 优于标准平均，同时你也能明白股价的标准平均能较好地反映股价地变化。</p>
<img src="https://picreso.oss-cn-beijing.aliyuncs.com/stocks231.png" alt="" style="zoom:50%;" />



<p>尽管并不完美，LSTM 在大部分情况下都能正确预测接下来的股价。而且你只能预测到股票接下来是涨是跌，而非股价的确切值。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>但愿本教程能帮到你，写这篇教程也让我受益匪浅。在本教程中，我了解到建立能够正确预测股价走势的模型是非常困难的。首先我们探讨了预测股价的动机。接下来我们了解到如何去下载并处理数据。然后我们介绍了两种可以向后预测一步的平均技术，这两种方法在预测多步时并不管用。之后，我们讨论了如何使用 LSTM 对未来的多步进行预测。最后，结果可视化，并发现这个模型（尽管并不完美）能出色地预测股价走势。</p>
<p>下面是本教程中对几个要点：</p>
<ol>
<li>股票价格/走势预测是一项极其困难的任务。就我个人而言，我认为任何股票预测模型都不完全正确，因此它们不应该被盲目地依赖。模型并不总是正确的。</li>
<li>不要相信那些声称预测曲线与真实股价完全重合的文章。那些取平均的方法在实践中并不管用。更明智的做法是预测股价走势。</li>
<li>模型的超参数会显著影响训练结果。所以最好使用一些诸如 Grid search 和 Random search 的调参技巧，下面是一系列非常重要的超参数：<strong>优化器的学习速率、网络层数、每层中的隐藏节点个数、优化器（Adam 是最好用的）以及模型的种类（GRU / LSTM / 增加 peephole connection 的 LSTM）</strong>。</li>
<li>在本教程中，由于数据集太小，我们根据测试损失函数来降低学习速率，这本身是不对的，因为这间接地将有关测试集的信息泄露到训练过程中。一种更好的处理方法是使用一个独立的验证集（与测试集不同），并根据验证集的性能降低学习速率。</li>
</ol>
<img src="https://picreso.oss-cn-beijing.aliyuncs.com/stocks.jpg" alt="" style="zoom:80%;" />


    </div>

    
        <hr class="fhr">
        <div id="vcomments"></div>
    
</div>
    <div class="footer" id="footer">
    <p><h4>版权所有 © 2020 | 作者: 刘训灼 | 主题 By <a class="theme-author" href="https://github.com/Xunzhuo/hexo-theme-coder" target="_blank" rel="noopener" style="font-size:14px; color: #969696">Coder</a></h4>
    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <span id="busuanzi_container_site_pv">本站浏览总访问量: <span id="busuanzi_value_site_pv"></span></span>
        <span class="post-meta-divider">|</span>
        <span id="busuanzi_container_site_uv">本站访问人数: <span id="busuanzi_value_site_uv"></span></span>
    
    <label class="el-switch el-switch-blue el-switch-sm" style="vertical-align: sub;">
        <input type="checkbox" name="switch" id="update_style">
        <span class="el-switch-style"></span>
    </label>

    <!--         <script type="text/javascript">
    var cnzz_protocol = (("https:" == document.location.protocol) ? "https://" : "http://");
    document.write(unescape("%3Cspan id='cnzz_stat_icon_1278548644'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/stat.php%3Fid%3D1278548644%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
    </script> -->
</p>
</div>

<input type="hidden" id="web_style" value="black">
<input type="hidden" id="valine_appid" value="NOsswOncKgc8HOxqo9oxIWlX-gzGzoHsz">
<input type="hidden" id="valine_appKey" value="z1FihjWEbS8uIfUQdmCtK7zz">

<script src="/libs/jquery.min.js"></script>


<script src="/libs/highlight/highlight.pack.js"></script>

<script src='//cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>

<script src="/js/js.js"></script>

<style type="text/css">
.v * {
color: #698fca;
}
.v .vlist .vcard .vhead .vsys {
color: #3a3e4a;
}
.v .vlist .vcard .vh .vmeta .vat {
color: #638fd5;
}
.v .vlist .vcard .vhead .vnick {
color: #6ba1ff;
}
.v a {
color: #8696b1;
}
.v .vlist .vcard .vhead .vnick:hover {
color: #669bfc;
}
</style>
    <script type="text/javascript" color="173,174,173" opacity='1' zIndex="-2" count="99" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
</body>
</html>
